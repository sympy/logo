#summary Information about sympycore

= Introduction =

As everytime with a fork, it's difficult to write "objective" wiki page about it, so for now, we just present opinions of individual people. All of them have write access to this wiki, so that they can change the wiki to reflect their opinions accurately (feel free to modify your opinion at any time - the point is not to show that someone is wrong, but to state our points clearly and maybe arrive at some consensus, also the full history is archived in the svn, so nothing is lost). People are sorted alphabetically.

== Fredrik Johansson ==

My opinion, like Pearu's, is that it would have been difficult to do the changes directly in sympy as it would break a lot of existing code, and effort would be spent getting that code to run instead of experimenting with the core.

== Kirill Smelkov ==

Yes, changing fundamental thing breaks a lot of code, but the changes (of course!) shall be targeted to improve the whole thing. Hence the need to bring it to the project. Yes, merging fundamental changes is a pain, but if the merge is kept in mind from the beginning, the pain can be lowered -- changes should be structured into smaller parts, and eventually, some of that smaller parts can be merged without breaking things too much, or at all.
*If* there is a motivation for the merge, everything can be easier, but when no merge is planned -- it is a disaster.

Let's see: what is better -- evolution or revolution?

evolution is changing things incrementally, in small steps and revolution usually breaks a lot of stuff. And this was proved to be bad most of the times.

ok, let's remember the previous "new" core.
What can be said about a merge? was it evolution or revolution?
How much time and effort did it take to restore the project?
Again, my point is that the merge have to be planned from the first minutes of a branch 
and yes, every branch is a fork (sort of micro)
But this works greatly when people intend to merge finally, and try to do their best to cooperate. And on the other way it leads to real forks.


Again, *if* there is a motivation for the merge, people usually try to find a way for their changes to be incorporated in, and they usually assist to port other code to new infrastructure if needed.

From the now-old "new" core we learnt, that a "merge" was just a breakage, and noone from the "new" core developers was intrested to keep thing in shape -- that is to ease and assits in adaptating other !SymPy code.

~~  . . . . . . . . . . . . . . . . . . .                                                                . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ~~

<kirr> It already did -- nothing prevented it to be developed on a branch, and when we switched to [http://www.selenic.com/mercurial/wiki Mercurial] it is much easier to develop on a separate branch, since it is in spirit of distributed development.

<kirr> Spawning a new project *is* release by itself!

<fredrik> i can't say i agree with that

<kirr> You'll find eventually that the amount of changes is *tons* and it is again impossible to "merge" it without breaking things. But at least I and I think Ondrej will object to the breakage. We did it once, and we learnt.

<kirr> separate issue tracker: just tag issues with say sympycore or something like that for easier search/etc...


=== Resume ===

[http://www.selenic.com/mercurial/wiki Mercurial] makes it easy to experiment in a branch.
That is to incrementally develop patches on some topic until they are ready.

Also, it is a good practice to merge ready bits into mainline in the process.

Release-early, release-often can be reformulated here as:

  _MERGE_-_EARLY_, _MERGE_ _OFTEN_


<kirr> The problem is that from the technical side, everything is ok to be in, but from someone's motivation side -- it is not.


== Ondřej Čertík == 

!SymPy uses a development model as described in SympyDevelopment, basically tests must pass and everything should be discussed in Issues, that is very good for a mature project and 
I very stronly believe that is the way to go - team work, open discussion about everything, cooperation. 

There are issues that could be improved though, such as speed, assumptions model, caching issues etc.

Nobody knows what is the best way to resolve these issues,
therefore one must experiment and that may temporarily break lots of
code. Thus such development needs to happen in a separate branch. We started to play with new ideas in the sympy-sandbox branch mainly by Pearu Peterson, but later Pearu decided to create his own project [http://code.google.com/p/sympycore sympycore], which has basically evolved into a fork of !SymPy.

Our plan in !SymPy is to see which ideas are good and which are bad in sympycore, let it settle for a while and then discuss them in Issues and implementing the good ones in !SymPy.  We believe that the way to go is incremental improvements of !SymPy, not a rewrite from scratch - we did that once in August 2006 and it broke a lot of things (some of which aren't working till now, but also some other things started to work), so that's not the way to go.
We also believe that having two incompatible symbolic manipulation libraries in Python is a bad thing. It's sad that sympycore developers don't implement the things directly in !SymPy, so that we need to duplicate their work in many cases, but we will port all good things finally, it will just take longer (in the meantime, some users will prefer to contribute to sympy, some other will choose sympycore).

With our strategy, !SymPy will always work and also it will benefit from new fundamental improvements.

== Pearu Peterson ==

What Fredrik said above is exactly why it is so difficult to fix
fundamental issues in sympy. Also, I agree with Ondřej that the 
SympyDevelopment model is a very good for a mature project.
From the fact that sympy has fundamental issues follows that
this development model cannot be applied strictly when there are
motivated people who are willing to work on fixing
the fundamental issues.

We all remember the pain of merging the sympy-research branch that
was a rewrite of my symbolic package to meet the interface developed in 
the original sympy. The merge never included all of the features in the branch
nor was all of the original functionality of sympy restored.
This does not sound good and hence the merge is remembered with pain.
However, if I remember correctly, the merge resulted a speedup up to
*150-1500 times* for various operations. I don't think that this kind of speedup
could have been achieved with a normal evolution of sympy. I do think
that the pain of merging was well-grounded and we should not actually
call this as a painful merge but an essential step forward in sympy development,
even when it contradicts a very good development model.

Implementing a CAS from scratch is not an easy task.
In fact, I think this is fundamentally a wrong way of approaching
the problem, i.e. to start with an _implementation_. If there is a
desire to have a CAS for a given programming environment, say Python,
then one should start working out a fundamental model of CAS taking
into account the possibilities and restrictions of the given programming
environment. When the model is worked out only then start implementing it 
as a final step. That would be ideal.

Fortunately, Python is close to being
an ideal programming language for prototype development where one can try
out different ideas and approaches by writing Python code from the beginning.
This is also how I see projects like sympy -- sympy is a prototype project
that aims to provide CAS for Python.
Hopefully in future it will be reliable and fast enough to solve real problems.
Let me repeat: implementing a CAS is not an easy task. Keeping in mind
what's said above, I would claim that too many developers will not
make this task any easier, especially in the early stages of development.

I believe that working out a reasonably good CAS model for Python requires
some vision what the model should include and what methods are suitable for
supporting this model efficiently.
I wrote my first Python program that aimed to perform basic symbolic
manipulations tasks about 9 years ago. After that I have tried to
implement a CAS for Python using very different approaches, starting
from manipulating Python AST trees to achieve some symbolic manipulation
effects, ending with creating Python interfaces to existing CA systems
of other environments such as GiNaC, Maxima using handwritten wrappers
or the Boost toolkit. With this experience in my bag, I dare to say that
I have some vision what the CAS model for Python should include and what
methods are suitable for implementing it in Python. Discussions and all the work
on sympy/sympycore with all of you have been most fruitful in searching
for a "perfect" way to implement a CAS for Python. Hopefully this
research will continue and one day we won't need to worry about changing
the core of sympy but instead work on extending sympy with new concepts and algorithms.


= Reactions =

Feel free to add any reactions you want to the above opinions. Feel free to change your opinion above at any time if you think it was not accurate - the point is to arrive at some consensus, or at least explain our motivations.

== Fredrik Johansson ==

== Kirill Smelkov ==

== Ondřej Čertík ==

_ The merge never included all of the features in the branch nor was all of the original functionality of sympy restored. This does not sound good and _

As far as i know, we took the whole core, as you wrote it and simply
ported all modules to it. So all features that you had should now be in
sympy. Which features weren't included?

_ hence the merge is remembered with pain. However, if I remember correctly, the merge resulted a speedup up to 150-1500 times for various operations. I don't think that this kind of speedup could have been achieved with a normal evolution of sympy. I do think that the pain of merging _

I think the main speedup was achieved by using __new__ instead of
__init__ and that should have been done incrementaly, because I spent literally weeks fixing issues with the
new core in sympy and the series still isn't working as it used to be
(it's true that some other problems went away). Some speedup is done
with caching, but as you have shown in sympycore, it is possible to
write fast CAS in python even without caching.

_ was well-grounded and we should not actually call this as a painful merge but an essential step forward in sympy development, even when it contradicts a very good development model. _

I think it was a mistake to do it, in the end it cost me much more
time, than just porting __init__ to _new_ and some other things (there
is also the ordering of the classes - I am not sure if it speeds
things up or down). Also, another very important point is, that people
stopped sending patches to the new core, because it's too complex to
understand. But they used to send patches
to the old core. Maybe it's inevitable for the core to be too complex,
but I still believe it could be done simple and fast.

_ this experience in my bag, I dare to say that I have some vision what the CAS model for Python should include and what methods are suitable for implementing it in Python. Discussions and all the work on _

Well - the new core, now in !SymPy is your (Pearu's) vision. It turned out it still needs more changes. Now you started sympycore, but I really don't see any guarantees that more changes will be needed to it and a new rewrite from scratch will happen? I don't think that's the way. Evolution, as Kirr says, that's the way.

Let me quote part of your email (see sympy mailinglist archives):

_After the merged core is stabilized then we should work hard to keep backward
compatibility as much as possible._

We merged that new core, but you don't seem to agree with this anymore, because sympycore is incompatible with your new core, now in !SymPy.
As to the experience, I am not sure it's that relevant, because I have
a plenty of experience too - I tried to fix your pyginac when you
stopped working on it, then I created swiginac together with Ola, played with ginac a lot
and wrote sympy, also I am quite involved in Sage.calculus. I also
tried and studied all CAS systems in the links on the sympy's webpage.

== Pearu Peterson ==

I am a bit disappointed that Ondřej feels that the merge was a mistake, I also spent
lots of time on working on it, more than I planned initially but I don't have regrets.
The porting was not complete in the sense that Lambda support was broken after
the merge, for instance.
Since the history of sympy should be available, one can always undo the merge..
But all this should be irrelevant at the moment, we should look to the future.

About the incompatibility between sympy/sympycore: I think this issue can be
easily resolved keeping in mind that they still share the same fundamental ideas:

  * classes are CamelCase, sympycore has also functions in CamelCase.
  * expressions are iterable in the same way, that is the fundamental feature that should keep sympy/sympycore extensions compatible or at least easily portable.
  * the module structure is similar, eg sympy is the parent package. In sympycore lots of functionality of sympy.core is moved to sympy.arithmetic package. This refactoring was needed in order to keep sympy.core clean and to be stictly a base package for subpackages like sympy.arithmetic, sympy.logical.symbolic, and sympy.logical.sets.
  * both miss a good assumption model: in !Sympy the assumption model is fragile, in !SympyCore there is no model implemented yet but it provides needed infrastructure for a better assumption model: constructors do not take assumptions and sympycore defines logical concepts.
  * btw, sympycore does not use ordered_classes anymore.. The Basic class in sympycore has been simplified considerably.