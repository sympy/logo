#summary Review of the 2010 Risch Integration GSoC Project
#labels GSoC

= About Me =

My name is Aaron Meurer.  I am an undergraduate student at New Mexico Tech double majoring in Mathematics and Computer Science.  This is my second year participating in Google Summer of Code.  Last year (2009), I also worked with !SymPy on improving the ODEs module (see the report for that project [http://code.google.com/p/sympy/wiki/ODEsModuleReport here].  
= Introduction =

My project was to implement the full Risch Algorithm for Symbolic Integration in !SymPy.  In particular, I worked on implementing the transcendental part of the algorithm.  My work consisted mostly of taking the algorithms from _[http://books.google.com/books?id=8SAaSd89sSkC&printsec=frontcover&dq=manuel+bronstein&hl=en&ei=Osp6TJK_IJPCsAPJ9oHuCg&sa=X&oi=book_result&ct=result&resnum=1&ved=0CCoQ6AEwAA#v=onepage&q&f=false Symbolic Integration I: Transcendental Functions]_ by Manuel Bronstein.  

Note that this is just an overview of my work this summer.  For more details, see the posts to my [http://asmeurersympy.wordpress.com/ blog], which also include more information on the theory behind the Risch Algorithm.  

You can see a copy of my full application for the project on the !SymPy !MediaWiki [http://wiki.sympy.org/wiki/User:Asmeurer/GSoC2010_Application here].

= GSoC Review =

== Beginning ==

If you are interested in how I originally became involved with !SymPy and Google Summer of Code, you should read my [http://code.google.com/p/sympy/wiki/ODEsModuleReport report] for last year's project. This year, I was already an active developer of !SymPy and already knew the procedures for Google Summer of Code, which helped me to focus on my project itself. 

== The GSoC Period ==

=== Preliminary Work ===

The Risch Symbolic Integration Algorithm is essentially a bunch of polynomial manipulation algorithms.  Therefore, all of these algorithms that I implemented are based on top of !SymPy's Polys module.  Prior to working on this project, I had only played with the Polys module a little, because I did not use it in my previous project, and because the module was new (it was merged into the !SymPy trunk in March of this same year).  Therefore, the first thing that I decided to do for my project was to familiarize myself with the Polys module in !SymPy.  The Polys module at that point had almost no doctests in the method/function docstrings, So the way that I chose to do this was to write doctests for all the major functions/methods in the Polys module.  This took me about two weeks to fully complete, after which I wrote almost 1000 doctests for the module.  Doing this forced me to understand what each function or method did, and in a way that required enough understanding to write a good doctest for it. In going through the functions and methods in the module, I also stumbled upon several bugs and efficiency problems, and I also added fixes for these in my development branch.  

I also had another good reason for doing this first instead of jumping straight into coding the Risch Algorithm algorithms, which is that I had to get through two chapters of theory in Bronstein's book first before I got to the part that started elaborating and proving the correctness of the algorithm.  

After documenting the Polys module, I still had a little bit to go in Bronstein's book before I got to some things that I could code, so I decided to go through the issues in the issue tracker that were related to integration.  For each of these, I labeled each of them, looked at what needed to be done to fix them, and I created a file of XFAILing tests in my branch for each failing integral, so that the progress for each could be tracked in the future. For a few, I was able to fix a bug or two to make them work.  

One thing that I did also after documenting the Polys module was attempt to rewrite the already existing heuristic Risch integration routine to use the new Polys module.  Now, I was able to successfully recode the function to use the new Polys, but I found that this actually made it _slower_, not faster.  The reason is that that function uses highly multivariate polynomials (hundreds of variables is not uncommon), and the current internal implementation  of polynomials in Poly is inefficient for these (it is a dense representation, rather than a sparse one).  Thus, this implementation was not useful directly, but it did help me to understand how that algorithm works, and also what are the bottlenecks in it that make it so slow (there are two, first, it uses what is currently a slow function is !SymPy, which is expand(), and second, it solves a massive system of linear equations, and solve_linear_system() is not as fast as it could be). 

== Coding the Algorithm ==

After I did these things, I had made my way in Bronstein's book to the point where there were algorithms that I could implement.  Bronstein's book gives pseudocode for almost all of the algorithms, so that implementing most of them was just a simple matter of translating the code given into SymPy Python.  

This is how the Transcendental Risch Algorithm works.  

  # Convert the input expression into a tower of transcendental differential extensions over Q(x).  For example, the expression exp(exp(1/x)) + log(x) would first be converted into exp(t0) + log(x) over Q(x, t0), where t0 = exp(1/x), then t1 + log(x) over Q(x, t0, t1), where t1 = exp(t0), and finally t1 + t2 over Q(x, t0, t1, t2), where t2 = log(x) (see the "Risch Integration Algorithm" series of posts on my [http://asmeurersympy.wordpress.com/ blog] for more information about this).  There is a stipulation that each extension must be transcendental over the previous extensions, and that the derivative of each extension term must be a polynomial in that term and a rational function in the terms already extended (for example D(t1) = -t1*t0/x**2).  

After this step, we recursively perform the following steps on each extension, starting at the top:

  # Perform some reduction algorithms to the input expression.  Each of these takes in a function and returns two parts.  The first part will be part of the integral of the function, and the second part will need to be integrated (symbolically, it reduces Integral(f(x), x) into g(x) + Integral(h(x), x)).  In each case, the remaining integral h(x) will be "simpler" in some sense to integrate.  The reduction methods are the Hermite Reduction, the Polynomial Reduction (when it is applicable), and the Residue Criterion/Reduction.  The last of these is also called a criterion because the reduction step might fail, in which case it will have proven that the function does not have an elementary integral.  

  # Integrating the function that remains after these steps is the most difficult part of the algorithm.  There are three main types of transcendental functions that can be integrated, exponential, primitive, and tangent.  An exponential (or hyperexponential) is a function that satisfies D(f) = Da*f, i.e., f = exp(a).  A primitive is a function whose derivative does not contain itself.  The most common example of this is log, because diff(log(x), x) = 1/x, which does not have log in it.  arctan() also fits in this category.  A tangent (or hypertangent) is a function that satisfies D(f) = Da*(f**2 + 1), i.e., f = tan(a).  

These three types of functions all have specialized algorithms required to integrate them.  Bronstein dedicates a whole chapter of his book to each.  The first is the exponential.  Integrating exponential functions is equivalent to solving what is known as the Risch Differential Equation, which is Dy + f*y = g, where f and g are given.  The primitive case requires solving a similar equation called the Parametric Risch Differential Equation, and the tangent case requires solving what is known as the Coupled DE System, which turns out to also be very similar to the Risch Differential Equation in solving.

=== Reduction Algorithms ===
The reduction algorithms were the first thing that Bronstein covered from the full algorithm, so these are the first things that I coded.  They were not difficult to code, and they provided a good start for the project.   Unfortunately, since they are only reduction algorithms, not full integration routines, they were only able to solve part of integration problems.  Furthermore, I had not yet coded the preparsing step (step 1), so all input to the algorithms had to be parsed by hand, which was a little meticulous, and not very good for showing them off.  

After doing this, I began to realize that I had made a few design mistakes in the API.  I still had only a rudimentary understanding of the recursive nature of the algorithm, so I originally coded the algorithms to only accept on extension, instead of arbitrarily many.  